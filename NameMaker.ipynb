{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"lq_16_09gdxi"},"outputs":[],"source":["#pip install torch torchvision torchaudio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dWtZfDt2gisd"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zHZ46RrbjitH"},"outputs":[],"source":["n_emb = 10\n","block_size = 8\n","batch_size = 4\n","n_hidden = 64\n","words = open('list.txt', 'r').read().splitlines()\n","vocab_size = sorted(list(set(''.join(words))))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RYyEmEe9x_27"},"outputs":[],"source":["stoi = {s:i for i,s in enumerate(vocab_size)}\n","itos = {i:s for s,i in stoi.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2893,"status":"ok","timestamp":1731488188844,"user":{"displayName":"blue Stone","userId":"03716969035560972928"},"user_tz":-60},"id":"JwccziWOkznq","outputId":"532b93e2-7a5a-4b71-e8f7-0ae2fd58fec5"},"outputs":[{"data":{"text/plain":["(torch.Size([4, 8]), torch.Size([4]))"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["def data_segmentation(n):\n","    Tdata = words[:n]\n","    Vdata = words[n:]\n","    return Tdata,Vdata\n","\n","def batch_creation(data, token_size):\n","    X, Y = [], []\n","    context = [0] * token_size\n","    for ch in data:\n","        for w in ch + '.':\n","            ix = stoi.get(w, None)\n","            if ix is None or ix >= len(vocab_size):\n","                continue\n","            X.append(context)\n","            Y.append(ix)\n","            if ix == 0:\n","                context = [0] * token_size\n","                break\n","            else:\n","                context = context[1:] + [ix]\n","    return X, Y\n","\n","\n","\n","def pick_batch(X, Y, batch_size):\n","    ix = torch.randint(len(X), (batch_size,)).tolist()\n","\n","    # Collect elements from `X` and `Y` using list comprehension\n","    xb = torch.stack([torch.tensor(X[i]) for i in ix])  # Use individual indices to access elements\n","    yb = torch.stack([torch.tensor(Y[i]) for i in ix])  # Use individual indices to access elements\n","\n","    return xb, yb\n","\n","\n","Xtr,Ytr = batch_creation(words[:80000],block_size)\n","Xv,Yv = batch_creation(words[80000:],block_size)\n","xb,yb = pick_batch(X=Xtr,Y=Ytr,batch_size=batch_size)\n","xb.shape,yb.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47,"status":"ok","timestamp":1731488188845,"user":{"displayName":"blue Stone","userId":"03716969035560972928"},"user_tz":-60},"id":"b9l-nAClyULO","outputId":"78bd7a95-f739-4a34-a94d-971ef6a6f1e0"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0, 0, 0, 0, 0, 0, 0, 0]  -----------> 5\n","[0, 0, 0, 0, 0, 0, 0, 5]  -----------> 3\n","[0, 0, 0, 0, 0, 0, 5, 3]  -----------> 5\n","[0, 0, 0, 0, 0, 5, 3, 5]  -----------> 1\n","[0, 0, 0, 0, 5, 3, 5, 1]  -----------> 40\n","[0, 0, 0, 5, 3, 5, 1, 40]  -----------> 50\n","[0, 0, 5, 3, 5, 1, 40, 50]  -----------> 39\n","[0, 5, 3, 5, 1, 40, 50, 39]  -----------> 32\n","[5, 3, 5, 1, 40, 50, 39, 32]  -----------> 3\n","[3, 5, 1, 40, 50, 39, 32, 3]  -----------> 5\n","[5, 1, 40, 50, 39, 32, 3, 5]  -----------> 2\n","[1, 40, 50, 39, 32, 3, 5, 2]  -----------> 41\n","[40, 50, 39, 32, 3, 5, 2, 41]  -----------> 32\n","[50, 39, 32, 3, 5, 2, 41, 32]  -----------> 56\n","[39, 32, 3, 5, 2, 41, 32, 56]  -----------> 3\n","[32, 3, 5, 2, 41, 32, 56, 3]  -----------> 5\n","[3, 5, 2, 41, 32, 56, 3, 5]  -----------> 32\n","[5, 2, 41, 32, 56, 3, 5, 32]  -----------> 3\n","[2, 41, 32, 56, 3, 5, 32, 3]  -----------> 5\n","[41, 32, 56, 3, 5, 32, 3, 5]  -----------> 32\n","tensor([[52, 51, 57,  3,  7, 43, 52, 53],\n","        [36,  3,  8, 40, 38, 49, 36, 38],\n","        [39, 45,  3, 11, 49, 52, 39, 46],\n","        [36, 49, 38,  3,  8, 46, 43, 33]]) -------------> tensor([36, 46, 51, 36])\n"]}],"source":["for x,y in zip(Xtr[0:20],Ytr[0:20]):\n","  print(x,\" ----------->\",y)\n","print(xb , '------------->',yb)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"bACt3F0qg2Mr"},"outputs":[],"source":["class Linear:\n","\n","  def __init__(self, fan_in, fan_out, bias=True):\n","    self.weight = torch.randn(fan_in, fan_out) / fan_in**0.5\n","    self.bias = torch.zeros(fan_out) if bias else None\n","\n","  def __call__(self, x):\n","    self.out = x @ self.weight\n","    if self.bias is not None:\n","      self.out += self.bias\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.weight] + ([] if self.bias is None else [self.bias])\n","\n","\n","\n","class Tanh:\n","    def __init__(self):\n","        self.tanh = torch.nn.Tanh()\n","\n","    def __call__(self,x):\n","        out = self.tanh(x)\n","        return out\n","\n","    def parameters(self):\n","        return []\n","\n","class Embedding:\n","\n","  def __init__(self):\n","    self.weight = torch.randn(len(vocab_size), n_emb)\n","\n","  def __call__(self, IX):\n","    self.out = self.weight[IX]\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.weight]\n","\n","class Flatten:\n","    def __call__(self, x):\n","        B, T, C = x.shape\n","        out = x.view(B, T*C)\n","        return out\n","\n","    def parameters(self):\n","        return []\n","\n","class SoftmaxModel:\n","    def __init__(self):\n","        self.softmax = torch.nn.Softmax(dim=1)\n","\n","    def forward(self, x):\n","        return self.softmax(x)\n","\n","class BatchNorm1d:\n","\n","  def __init__(self, dim, eps=1e-5, momentum=0.1):\n","    self.eps = eps\n","    self.momentum = momentum\n","    self.training = True\n","    # parameters (trained with backprop)\n","    self.gamma = torch.ones(dim)\n","    self.beta = torch.zeros(dim)\n","    # buffers (trained with a running 'momentum update')\n","    self.running_mean = torch.zeros(dim)\n","    self.running_var = torch.ones(dim)\n","\n","  def __call__(self, x):\n","    # calculate the forward pass\n","    if self.training:\n","      if x.ndim == 2:\n","        dim = 0\n","      elif x.ndim == 3:\n","        dim = (0,1)\n","      xmean = x.mean(dim, keepdim=True) # batch mean\n","      xvar = x.var(dim, keepdim=True) # batch variance\n","    else:\n","      xmean = self.running_mean\n","      xvar = self.running_var\n","    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalize to unit variance\n","    self.out = self.gamma * xhat + self.beta\n","    # update the buffers\n","    if self.training:\n","      with torch.no_grad():\n","        self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * xmean\n","        self.running_var = (1 - self.momentum) * self.running_var + self.momentum * xvar\n","    return self.out\n","\n","  def parameters(self):\n","    return [self.gamma, self.beta]\n","\n","class Sequential:\n","\n","  def __init__(self, layers):\n","    self.layers = layers\n","\n","  def __call__(self, x):\n","    for layer in self.layers:\n","      x = layer(x)\n","    self.out = x\n","    return self.out\n","\n","  def parameters(self):\n","    return [p for layer in self.layers for p in layer.parameters()]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"elapsed":44,"status":"ok","timestamp":1731488188845,"user":{"displayName":"blue Stone","userId":"03716969035560972928"},"user_tz":-60},"id":"bxa-ZTq__MRe","outputId":"5c34e397-1be1-4cab-d2b8-0e9054fcdc32"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'model = BiagrammModel()\\n  # Use Adam optimizer for better stability\\n\\nfor i in range(50000):\\n    xb, yb = pick_batch(X, Y, batch_size)\\n    logits = model(xb)\\n    loss = F.cross_entropy(logits, yb)  # Don\\'t apply Softmax before cross_entropy\\n\\n    for p in model.parameters():\\n        p.grad = None\\n\\n    loss.backward()\\n\\n    for p in model.parameters():\\n        p.data += -0.1 * p.grad\\n\\n\\n\\n    # Print the loss every 1000 iterations\\n    if i % 1000 == 0:\\n        print(f\"Step {i}, Loss: {loss.item()}\")'"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"model = BiagrammModel()\n","  # Use Adam optimizer for better stability\n","\n","for i in range(50000):\n","    xb, yb = pick_batch(X, Y, batch_size)\n","    logits = model(xb)\n","    loss = F.cross_entropy(logits, yb)  # Don't apply Softmax before cross_entropy\n","\n","    for p in model.parameters():\n","        p.grad = None\n","\n","    loss.backward()\n","\n","    for p in model.parameters():\n","        p.data += -0.1 * p.grad\n","\n","\n","\n","    # Print the loss every 1000 iterations\n","    if i % 1000 == 0:\n","        print(f\"Step {i}, Loss: {loss.item()}\")\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"2CrfzokTG2Wy"},"outputs":[],"source":["n_emb = 10\n","n_hidden = 64\n","model = Sequential([\n","  Embedding(),\n","  Flatten(), Linear(n_emb * block_size, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","  Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","  Linear(n_hidden, n_hidden, bias=False), BatchNorm1d(n_hidden), Tanh(),\n","  Linear(n_hidden, len(vocab_size)),\n","])\n","\n","\n","with torch.no_grad():\n","  model.layers[-1].weight *= 0.1\n","\n","parameters = model.parameters() # number of parameters in total\n","for p in parameters:\n","  p.requires_grad = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Pz7QnPaszDL2"},"outputs":[],"source":["for layer in model.layers:\n","  layer.training = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25983,"status":"ok","timestamp":1731488214790,"user":{"displayName":"blue Stone","userId":"03716969035560972928"},"user_tz":-60},"id":"esxMLpen2MWo","outputId":"037c7335-781a-46cc-880c-8f9a09b065a6"},"outputs":[{"name":"stdout","output_type":"stream","text":["      0/  10000: 4.0657\n","   1000/  10000: 4.0109\n","   2000/  10000: 3.9694\n","   3000/  10000: 3.8732\n","   4000/  10000: 3.7817\n","   5000/  10000: 3.6752\n","   6000/  10000: 3.6041\n","   7000/  10000: 3.5659\n","   8000/  10000: 3.4351\n","   9000/  10000: 3.4685\n"]}],"source":["# same optimization as last time\n","max_steps = 10000\n","batch_size = 32\n","lossi = []\n","\n","for i in range(max_steps):\n","\n","  # minibatch construct\n","\n","  Xb, Yb = pick_batch(Xtr,Ytr,batch_size) # batch X,Y\n","\n","\n","    # forward pass\n","  logits = model(Xb)\n","\n","  loss = F.cross_entropy(logits, Yb) # loss function\n","\n","  # backward pass\n","  for p in parameters:\n","    p.grad = None\n","  loss.backward()\n","\n","  # update: simple SGD\n","  #lr = 0.01 if i < 2500 else\n","  lr = 0.001 # step learning rate decay\n","  for p in parameters:\n","    p.data += -lr * p.grad\n","\n","  # track stats\n","  if i % 1000 == 0: # print every once in a while\n","    print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n","  lossi.append(loss.log10().item())\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UFxCb-jOsa_D"},"outputs":[],"source":["for layer in model.layers:\n","  layer.training = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"elapsed":135,"status":"error","timestamp":1731488214790,"user":{"displayName":"blue Stone","userId":"03716969035560972928"},"user_tz":-60},"id":"L-290vb3shJG","outputId":"8394fd15-9f9a-453e-bfeb-e605b046abdb"},"outputs":[{"ename":"KeyError","evalue":"0","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-0c1ce3c83717>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-31-0c1ce3c83717>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mKeyError\u001b[0m: 0"]}],"source":["for i in range(20):\n","    out = []\n","    context = [0] * block_size\n","    while True:\n","      logits = model(torch.tensor([context]))\n","      probs = F.softmax(logits, dim=1)\n","      ix = torch.multinomial(probs, num_samples=1).item()\n","      context = context[1:] + [ix]\n","      out.append(ix)\n","      if ix == 3:\n","        break\n","\n","    print(''.join(itos[i] for i in out))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aewiU_nku5HA"},"outputs":[],"source":["stoi"]}],"metadata":{"colab":{"provenance":[{"file_id":"1yjMqntxCFTsJKCMDUFtPe4A-9Zwvtf6m","timestamp":1731439708482},{"file_id":"1Y7ezRcioGoc18Dy0uXClm1G0o6QCuy8_","timestamp":1731322969735}],"authorship_tag":"ABX9TyOa10aksuE2JJitElDBykO7"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
